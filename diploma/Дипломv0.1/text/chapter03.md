# Моделирование модуля активного управления трафиком сети передачи данных

## Создание модуля для среды Mininet

В главе 2 уже был рассмотрен способ моделирования сети в среде Mininet. Данный способ включает в себя создание программы на языке программирования Python. В программе описывается топология сети, манипуляции с сетью, ее старт и завершение. Написав пару таких сетей, можно столкнуться с мыслью, что части кода идентичны друг другу, а каждое редактирование и исследование сети занимает время. Можно написать автоматизированное решение, которое требует только задание нужных сетевых элементов и их конфигураций, а программа сама считает данные, создаст сеть, построит графики сетевых характеристик и т. д. Данная идея будет описана далее в этой главе. 

Для начала требуется выбрать формат конфигурационного файла. Выбор формата конфигурационного файла производится из собственных предпочтений и удобства анализа файла. В данной работе будет использован формат toml [@toml]. Определим объекты сети, которые мы будем описывать в конфигурационном файле: хосты, коммутаторы, соединения, мониторинговые характеристики, команды qdisc для интерфейсов коммутатора. 

Имея подобный конфигурационный toml-файл, его можно прочесть с помощью средств Python, обработать и положить требуемые значения в объекты. Такой подход позволяет строить сколь угодно большие топологии без правки логики приложения. На основе данного файла можно построить программу, использующую диаграмму активностей, показанную на рис.[-@fig:30001]

![Диаграмма активностей приложения](act_dia.png){ #fig:30001 width=70% }

Программу можно разделить на такие модули как: мониторинг сети, построение графиков сетевых характеристик, модуль модели сети, который включает в себя топологию сети и два предыдущих элемента. Исходя из этого можно построить диаграмму классов приложения, показанную на рис.[-@fig:30002].

![Диаграмма классов приложения](class_dia.png){ #fig:30002 width=70% }

Главным классом, включающим в себя все остальные, является CustomModel. В методе simulation создаются объекты классов Monitor, mininet.net.Mininet, CustomTopology и NetStatsPlotter. Рассмотрим подробнее классы, создаваемые в методе simulation:

- mininet.net.Minet — предоставляемый Mininet API класс, отвечающий за создание сети с топологией, указанной в CustomTopology;
- CustomTopology — класс топологии сети;
- Monitor — класс, в котором происходят замеры сетевых характеристик исследуемой сети;
- NetStatsPlotter — класс, объект которого занимается построением графиков сетевых характеристик.

Код классов NetStatsPlotter, Monitor, CustomTopology и CustomModel находятся в [приложении A](#appendix1), [приложении B](#appendix2), [приложении C](#appendix3) и [приложении D](#appendix4) соответственно. 

Точкой входа в данную программу будет файл main.py. Содержимое данного файла представлено ниже:

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
]
{python}
'''
#!/usr/bin/python3.8

import argparse
from model.CustomModel import CustomModel

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    h = "Файл конфигурации"
    parser.add_argument('-c', '--config', type=str, help=h)
    args = parser.parse_args()
    if args.config:
        top = CustomModel()
        top.configure_model(args.config)
        top.simulation()
    else:
        print("Введите название конфиг-файла")

\end{minted}

Это обычный скрипт на языке программирования Python, который создает модель нашей сети из конфигурационного файла, переданного параметром командной строки. Запустить данный скрипт можно с помощью команды

\begin{minted}[breaklines]{bash}
sudo ./main.py -c config/pfifo_config.toml
\end{minted}

Параметр **-c** отвечает за местоположение конфигурационного файла. Естественно, перед запуском скрипта требуется задать право на исполнение файла. Делается это с помощью команды

\begin{minted}[breaklines]{bash}
chmod +x main.py
\end{minted}

После запуска программы в каталоге приложения появится директория с именем, которое было указано в toml-файле. В ней содержатся графики изменения сетевых характеристик и сырые данные, которые были обработаны объектом класса NetStatsPlotter.

## Тестирование программного модуля

У нас имеется готовая программа в наличии и нам следует ее протестировать. Для начала требуется описать сеть, заполнить конфигурационный файл по характеристикам заданной сети, запустить программу и исследовать сетевые характеристики сети передачи данных. 

Пусть у нас имеется сеть, заданная топологией, приведенной на рис.[-@fig:30003].

![Топология исследуемой сети](example_topo.png){ #fig:30003 width=70% }

Характеристики данной сети:

Предполагается, что в данной сети будут действовать следующие правила:

- скорость передачи данных ограничена;
- максимальная пропускная способность соединения h1-s1 равна 100 Мбит/с;
- максимальная пропускная способность соединения s2-h2 равна 50 Мбит/с;
- на коммутаторе s2 стоит дисциплина обработки очередей FIFO с максимальным количеством пакетов, равным 30;
- потери в сети составляют 0.001%;
- задержка имеет нормальное распределение с математическим ожиданием в
30 мс и с дисперсией в 7 мс.
- в сети работает алгоритм для работы с перегрузками TCP Reno [@rfc2001].

Опишем данные характеристики в конфигурационном файле.

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
]
{kconfig}
'''
# device settings
[devices]
    [devices.h1]
        name = "h1"
        ip = "10.0.0.1"
        cmd = [
            "sysctl -w net.ipv4.tcp_congestion_control=reno"
        ]
    [devices.h2]
        name = "h2"
        ip = "10.0.0.2"
        cmd = [
            "sysctl -w net.ipv4.tcp_congestion_control=reno"
        ]

# switch settings
[switches]
    [switches.s1]
        name = "s1"
    [switches.s2]
        name = "s2"

# link settings
[links]
pairs = [
    ["h1", "s1"],
    ["s1", "s2"],
    ["s2", "h2"]
]
cmd = [
    "tc qdisc replace dev s1-eth2 root handle 10: tbf rate 100mbit burst 50000 limit 150000",
    "tc qdisc add dev s1-eth2 parent 10: handle 20: netem loss 0.001% delay 30ms 7ms distribution normal",
    "tc qdisc replace dev s1-eth1 root handle 10: tbf rate 100mbit burst 50000 limit 150000",
    "tc qdisc add dev s1-eth1 parent 10: handle 20: netem loss 0.001% delay 30ms 7ms distribution normal",
    "tc qdisc replace dev s2-eth2 root handle 10: tbf rate 50mbit burst 25000 limit 75000",
    "tc qdisc add dev s2-eth2 parent 10: handle 15: pfifo limit 30",
    "tc qdisc replace dev s2-eth1 root handle 10: tbf rate 50mbit burst 25000 limit 75000"
]

[monitoring]
monitoring_time = 30
monitoring_interval = 0.1
host_client = "h1"
host_server = "h2"
interface = "s2-eth2"
iperf_file_name = "iperf.json"
iperf_flags = ""
queue_data_file_name = "qlen.data"
plots_dir = "plots_dir_first"
\end{minted}

В представленном toml-файле раздел **devices** отвечает за настройку конечных узлов сети, раздел **switches** отвечает за настройку коммутаторов, а раздел **links** отвечает за настройку соединений узлов сети и конфигурацию интерфейсов коммутаторов.

На хостах указывается ip-адрес, имя хоста и алгоритм работы с перегрузками. На коммутаторах прописывается только имя, однако, список настроек можно расширить, изменив программную логику в классе с топологией. В разделе **links** явно указывается, какие пары сетевых устройств соединяются, и команды, которые настраивают дисциплину очередей на интерфейсах. Важно уточнить, что соединения на коммутаторе происходят последовательно, т. е. если первым идет подключение h1-s1, то интерфейсом на коммутаторе, отвечающим за данное соединение, является интерфейс s1-eth1. Если, например, подключить еще одно устройство к коммутатору, то интерфейсом коммутатора в соединении будет s1-eth2, и так далее. Данный момент следует учитывать при установке правил дисциплин очередей на интерфейсах.

Также, в toml-файле имеется блок **monitoring**, в котором заданы следующие параметры: 

- monitoring_time --- время мониторинга сети в секундах;
- monitoring_interval --- интервалы между замерами длины очереди в секундах;
- host_client --- узел, который будет отправлять данные;
- host_server --- узел, который будет принимать данные;
- interface --- интерфейс, на котором будет мониторится размер очереди;
- iperf_file_name --- имя файла с отчетом мониторинга iperf;
- iperf_flags --- iperf-флаги клиента;
- queue_data_file_name --- имя файла с отчетом мониторинга длины очереди;
- plots_dir --- директория со всеми графиками сетевых характеристик.

Все параметры являются обязательными.

Ра

