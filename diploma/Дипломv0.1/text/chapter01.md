# Моделирование сетей в среде Mininet и анализ их производительности

## Обзор исследований в области моделирования в среде Mininet

Качество работы сетевого приложения определяется, в значительной степени, качествами линии передачи данных, сетевых устройств и работающих в них алгоритмах обработки потока данных.  Современные сети передачи данных не могут обеспечить нужный уровень качества обслуживания по ряду причин. Одна из них – слабая взаимосвязь физических сетевых элементов разных уровней. Контроль передачи данных лежит на каждом устройстве отдельно, что, в некоторых случаях, ведет к многочисленным потерям данных и задержкам. Консорциум Open Networking Foundation (ONF) [@onf] предложил решение данной проблемы: отделить уровень контроля передачи данных от сетевого устройства и перенести все эти заботы на некоторый контроллер. Управление данным контроллером ведется централизовано с помощью протокола OpenFlow [@openflow], что помогает установить нужный уровень предоставления услуг для конкретного приложения. Такое устройство сети консорциум ONF назвал Software-defined Networking (SDN) [@sdn]. Для изучения производительности сетей SDN методом моделирования организация ONF разработала эмулятор сети Mininet. 

В работе [@article_ros] речь идет об имитационном моделировании сети SDN с помощью средств Mininet и измерении производительности сети. Были затронуты следующие показатели производительности: RTT [@rtt] для каждого направления связи, пропускная способность ветвей и направлений связи, величина задержки на сетевых элементах, загрузка портов OpenFlow Switch, элементы сети с наибольшей задержкой, число обслуженных и потерянных пакетов. Mininet хорошо подходит для задач имитационного моделирования и исследований общей эффективности работы сети, однако, для создания сети требуется умение писать программы и знание Mininet API.  

Работа [@article_masdntp] представляет собой подробное руководство по взаимодействию с Mininet, как с помощью CLI [@cli], так и с помощью написания программ на языке программирования Python. Авторы показывают простоту создания сетевых топологий различной сложности, такие как Minimal, Single, Linear, Tree, Reversed. Также, в работе представлена программа, которая создает собственную сеть внутри Mininet и проводит простой анализ ее производительности. Созданная сеть детерминирована и состоит всего из 3 узлов, соединенных коммутатором. Анализ работы сети не имеет смысла, так как сеть создана, скорее, для демонстрации принципов работы с Mininet, а не для исследований. Из данной работы видно, что Mininet отлично подходит для исследований производительности сети и сетевых компонентов, благодаря своей простоте и настройке.

Идея автоматизации процесса создания топологий сети возникает сама собой, после написания двух-трех программ. Авторы работы [@article_iosctfim] описывают способ такой автоматизации. Способ основан на создании конфигурационного файла, в котором описаны основные правила адресации, создания сетевых устройств и соединений между ними. Чтение конфигурационного файла происходит в программе, написанной на языке программирования Python. Данный способ заметно ускоряет развертывание сети, избавляя исследователя от постоянных модификаций программного кода.

## Обзор исследований в области анализа производительности сетей и сетевых компонентов в среде Mininet

Простое моделирование сети не дает информации об ее производительности. Нужно провести качественный анализ работы сетевых компонентов, рассчитать пропускную способность соединения, количество потерянных и доставленных пакетов и т. д. Работа [@article_paoasdnum] является хорошим началом для изучения методов анализа производительности сети. Авторы исследуют задержки в сети при передаче данных и сравнивают показатели в HDN и SDN. Hardware Defined Network (HDN) --- привычные нам сети, где управление передачи данных лежит на устройствах сетевого и канального уровней. Работа показала, что SDN справляется с работой лучше и средняя задержка передачи данных в ней ниже (3.891 мс против 8.277 мс). Однако, стоит заметить, что здесь речь идет о передаче простого ICMP пакета, а не потока TCP/UDP трафика. 

Работа [@article_paoccmisdn] является более интересным примером анализа производительности сети в Mininet. В ней рассматриваются вопросы оценки производительности механизмов для эффективной работы с перегрузки в SDN. Авторы оценивают общую производительность сети, сравнивая ее с производительностью сети, которая использует Link Layer Discovery Protocol (LLDP) [@lldp]. Данный протокол канального уровня позволяет сетевому оборудованию оповещать оборудование, работающее в локальной сети, о своём существовании и передавать ему свои характеристики. Протокол отлично подходит для новой концепции построения сетей SDN, которую мы рассматривали ранее, так как позволяет SDN-контроллеру знать характеристики элементов сети и в зависимости от этого управлять потоками трафика. Оценка производительности основывается на трех пунктах: 

  - Уровень потери пакетов;
  - Уровень доставки пакетов;
  - Общая пропускная способность.

Данные оценки определяются для каждой итерации исследования. Всего таких итераций 4, и они имеют следующие сетевые топологии: 

  1. 1 SDN-контроллер, 4 коммутатора, 1 хост, 4 соединения;
  2. 1 SDN-контроллер, 15 коммутаторов, 16 хостов, 30 соединений;
  3. 1 SDN-контроллер, 40 коммутаторов,81 хост, 120 соединений;
  4. 1 SDN-контроллер, 85 коммутаторов, 256 хостов, 340 соединений.

В ходе работы были построен график, которые отображают зависимость сетевой характеристики от сетевой топологии для обычной сети и сети, которая использует LLDP. На графиках видно, что сеть второго типа показывает лучший уровень производительности для каждой сетевой характеристики передачи данных: ниже уровень потерь пакетов, выше уровень доставки пакетов, выше общая пропускная способность. 

Mininet отлично подходит для проведения исследований поведенческих особенностей сетевых компонентов. Однако, можно также провести исследование работоспособности и производительности сетевых протоколов и приложений. Авторы статьи [@article_apeotba] исследуют производительность алгоритма для эффективной работы с перегрузками BBRv2. Анализ работы алгоритма, презентацию и исходный код можно найти в [@bbrv2]. BBRv1 – нестандартный алгоритм управления перегрузками разработанный в Google, который не использует потерю пакетов как маркет для снижения скорости отправки. Алгоритм BBRv1 [@bbrv1], в сравнении с предшествующими алгоритмами, выдает большую пропускную способность для потоков данных при равных условиях. Одним из минусов алгоритма является его слабая совместимость с более старыми алгоритмами, используемыми в сети, и алгоритм BBRv2 создан как раз для исправления данной бреши.
В исследовании средствами Mininet создается сеть, имеющая 100 узлов отправителей и 100 узлов получателей. Отправители и получатели связаны между собой сетью из 3-х коммутаторов, каждый из который имеет свою задачу: 
- коммутатор 1: является точкой входа для узлов-отправителей, эмулирует потери и задержки данных с помощью средств NetEm [@tc_netem], соединен с коммутатором 2;
- коммутатор 2: эмулирует «узкое горлышко» между отправителями и получателями, ограничивая скорость передачи данных до 1 Гбит/с. Ограничивание передачи осуществляется с помощью дисциплины очередей TBF [@tc_tbf].
 - коммутатор 3: соединяет коммутатор 2 и хосты получатели. 

В ходе работы были исследованы и сравнены алгоритмы CUBIC [@rfc8312], BBRv1, BBRv2 на такие сетевые характеристики: пропускная способность, индекс справедливости [@rfc5166], сосуществование. Результаты показывают, что BBRv2 обеспечивает лучшее сосуществование с потоками, использующие алгоритм CUBIC, по сравнению со своим предшественником. Кроме того, BBRv2 способен обеспечить более справедливую долю пропускной способности по сравнению с BBRv1, когда сетевые условия, такие как пропускная способность и задержка, динамически изменяются. 